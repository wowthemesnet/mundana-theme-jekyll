<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.8.5">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2019-11-02T18:18:12+09:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">SpellOnYou</title><subtitle>Be afraid only of standing still. Remain fresh, body and soul.</subtitle><entry><title type="html">Lecture 08 - Deep Learning From Foundations-part2</title><link href="http://localhost:4000/2019/11/note08-fastai-2/" rel="alternate" type="text/html" title="Lecture 08 - Deep Learning From Foundations-part2" /><published>2019-11-01T00:00:00+09:00</published><updated>2019-11-01T00:00:00+09:00</updated><id>http://localhost:4000/2019/11/note08-fastai-2</id><content type="html" xml:base="http://localhost:4000/2019/11/note08-fastai-2/">&lt;h4 id=&quot;frobenius-norm&quot;&gt;Frobenius norm&lt;/h4&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;$ | A |&lt;em&gt;F = \left( \sum&lt;/em&gt;{i,j=1}^n&lt;/td&gt;
      &lt;td&gt;a_{ij}&lt;/td&gt;
      &lt;td&gt;^2 \right)^{1/2} $ Â &lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;ul&gt;
  &lt;li&gt;above converted into Â &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;code&gt;(m\*m).sum().sqrt()&lt;/code&gt;Â &lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Plus, donâ€™t suffer from mathmatical symbols. He also copy and paste that equations from wikipedia.&lt;/li&gt;
  &lt;li&gt;and if you need latex form, download it from archive.&lt;/li&gt;
&lt;/ul&gt;

&lt;h6 id=&quot;what-is-the-meaning-of-elementwise&quot;&gt;What is the meaning of elementwise?&lt;/h6&gt;
&lt;ul&gt;
  &lt;li&gt;We do not calculate each component. But all of the component at once. Because, length of column of A and row of B are fixed.&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;how-much-time-we-saved&quot;&gt;How much time we saved?&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/4.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;So now that takes 1.37ms. We have removed one line of code and it is a 178 times fasterâ€¦&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;#TODO
I donâ€™t know where the &lt;code class=&quot;highlighter-rouge&quot;&gt;5&lt;/code&gt; from. but keep it.
Maybe this is related with frobenius normâ€¦?
Â Â 
as a result, &lt;strong&gt;the code before&lt;/strong&gt;Â 
Â &lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;for k in range(ac):
    c[i,j] += a[i,k] + b[k,j]&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;the code afterÂ 
Â Â &lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;c[i,j] = (a[i,:] * b[:,j]).sum()&lt;/code&gt;
Â Â Â &lt;/p&gt;

&lt;p&gt;To compare it (result betweet &lt;em&gt;original&lt;/em&gt; and &lt;em&gt;adjusted&lt;/em&gt; version) we use not test_eq but other function. The reason for this is that due to rounding errors from math operations, matrices may not be exactly the same. As a result, we want a function that will â€œis a equal to b &lt;strong&gt;within some tolerance&lt;/strong&gt;â€&lt;/p&gt;

&lt;p&gt;Â 
`#export
def near(a,b): 
    return torch.allclose(a, b, rtol=1e-3, atol=1e-5)&lt;/p&gt;

&lt;p&gt;def test_near(a,b): 
    test(a,b,near)&lt;/p&gt;

&lt;p&gt;test_near(t1, matmul(m1, m2))`
Â &lt;/p&gt;

&lt;h3 id=&quot;broadcasting&quot;&gt;Broadcasting&lt;/h3&gt;

&lt;p&gt;Now, we will use the broadcasting and remove&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;c[i,j] = (a[i,:] * b[:,j]).sum()&lt;/code&gt;
Â &lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;How it works?&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;a=tensor([[10,10,10],
          [20,20,20],
          [30,30,30]])
b=tensor([1,2,3,])
a,b&lt;/code&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;(tensor([[10, 10, 10],
         [20, 20, 20],
         [30, 30, 30]]), tensor([1, 2, 3]))&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;a+b&lt;/code&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;tensor([[11, 12, 13],
        [21, 22, 23],
        [31, 32, 33]])&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/3.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: center;&quot;&gt;Figure 2. demonstrated how array **b** is broadcast to compatible with **a** *Adopted from* [*numpy_tutorial*](https://www.tutorialspoint.com/numpy/numpy_broadcasting.htm)&lt;/p&gt;
&lt;p&gt;Â &lt;/p&gt;

&lt;p&gt;there is no loop, but it seems there is exactly the loop.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;This is not from jeremy but i wondered How to broadcast an array by columns?&lt;/strong&gt;&lt;/p&gt;

&lt;h3 id=&quot;reference&quot;&gt;Reference&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://mathworld.wolfram.com/TensorRank.html&quot;&gt;TensorRank&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://forums.fast.ai/t/forum-markdown-notes-lesson-8/41896&quot;&gt;ti note&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>dionne</name></author><category term="featured" /><summary type="html">Frobenius norm</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:4000/assets/images/5.png" /></entry><entry><title type="html">Why am I not listed as a contributor to a project that merged my PR?</title><link href="http://localhost:4000/2019/10/Git-Merge/" rel="alternate" type="text/html" title="Why am I not listed as a contributor to a project that merged my PR?" /><published>2019-10-30T00:00:00+09:00</published><updated>2019-10-30T00:00:00+09:00</updated><id>http://localhost:4000/2019/10/Git-Merge</id><content type="html" xml:base="http://localhost:4000/2019/10/Git-Merge/">&lt;h3 id=&quot;how-did-i-come-to-that-repository&quot;&gt;How did I come to that repository?&lt;/h3&gt;

&lt;p&gt;When Iâ€™m stuck, I would prefer to code, than to go deep in theory. (It must be so.. too much to understand ğŸ¤’)Â 
It was &lt;a href=&quot;https://arxiv.org/pdf/1810.04805.pdf&quot;&gt;BERT released by Google AI&lt;/a&gt; I felt keenly the necessity of implementing, because not only couldnâ€™t understand the way they figured out positional encoding formula, but how it actually works.Â What does it mean to â€œscaleâ€ dot product in Attention? (Now I know itâ€™s far from my section ğŸ˜‚)Â &lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;&amp;quot;https://www.tensorflow.org/images/tutorials/transformer/scaled_attention&amp;quot;&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p style=&quot;text-align: center;&quot;&gt;Figure 1. Scaled Dot Product. *Adopted from* [*tensorflow blog*](www.tensorflow.org)&lt;/p&gt;
&lt;p&gt;Â &lt;/p&gt;

&lt;h3 id=&quot;what-was-the-code-error&quot;&gt;What was the code error?&lt;/h3&gt;

&lt;p&gt;For implement code in paper, I read the papers &lt;a href=&quot;https://arxiv.org/pdf/1706.03762.pdf&quot;&gt;Transformer&lt;/a&gt; and &lt;a href=&quot;https://arxiv.org/pdf/1810.04805.pdf&quot;&gt;BERT&lt;/a&gt;, structured the model, and refered the othersâ€™ code.Â Â &lt;/p&gt;

&lt;p&gt;Meanwhile, I found out a small error in tokenization process, which was changing a token into [MASK], enabled bidirectional representation.&lt;/p&gt;

&lt;h3 id=&quot;ive-made-pr-and-got-merged-but-i-was-not-in-contributors-why&quot;&gt;Iâ€™ve made PR, and got merged. But I was not in contributors. Why?&lt;/h3&gt;

&lt;p&gt;Actually I happened to know I was exception, after that I became curious.Â 
Soâ€¦ Doesnâ€™t it means we can cover up someoneâ€™s traces?Â 
Did I something wrong?Â &lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/2.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p style=&quot;text-align: center;&quot;&gt;Figure 2. Merged Pull request *Adopted from* [*graykode project*](https://github.com/graykode/nlp-tutorial/pull/9)&lt;/p&gt;
&lt;p&gt;Â &lt;/p&gt;

&lt;p&gt;According to &lt;a href=&quot;https://help.github.com/en/github/collaborating-with-issues-and-pull-requests/about-pull-request-merges&quot;&gt;About pull request merges&lt;/a&gt; and &lt;a href=&quot;https://git-scm.com/docs/git-merge#_fast_forward_merge&quot;&gt;git&lt;/a&gt;, itâ€™s because a person who has a write permission had selected squash (fast-forward) merge option on a pull request.Â 
Since it dose fetch from the remote first and immediately execute &lt;code&gt;git merge&lt;/code&gt; to create a merge commit, this option append a commit to master without creating a commit.&lt;/p&gt;

&lt;h4 id=&quot;reference&quot;&gt;Reference&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://mchromiak.github.io/articles/2017/Sep/12/Transformer-Attention-is-all-you-need/&quot;&gt;MichaÅ‚ Chromiakâ€™s blog&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://shinglyu.com/web/2016/11/08/servo-rebase-and-squash-guide.html&quot;&gt;Shing Lyu blog&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://git-scm.com/docs/git-merge#_fast_forward_merge&quot;&gt;Git-docs&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://help.github.com/en/github/setting-up-and-managing-your-github-profile/why-are-my-contributions-not-showing-up-on-my-profile&quot;&gt;Github: why are my contributions are not showing on my profile&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.atlassian.com/git/tutorials/syncing/git-fetch&quot;&gt;atlassian-gitfetch&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>dionne</name></author><category term="featured" /><summary type="html">How did I come to that repository?</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:4000/assets/images/1.png" /></entry><entry><title type="html">5 reasons took much time to setting GPU for fast.ai than I expected</title><link href="http://localhost:4000/2019/10/GPU-time/" rel="alternate" type="text/html" title="5 reasons took much time to setting GPU for fast.ai than I expected" /><published>2019-10-23T00:00:00+09:00</published><updated>2019-10-23T00:00:00+09:00</updated><id>http://localhost:4000/2019/10/GPU-time</id><content type="html" xml:base="http://localhost:4000/2019/10/GPU-time/">&lt;h2 id=&quot;motivation&quot;&gt;Motivation&lt;/h2&gt;

&lt;p&gt;Before now, me as a undergraduate student, I was parsimony who usually depend on colab, kaggle, friendâ€™s server(occasional) whenever i need GPU..Â 
Â 
And this time itâ€™s been for a while to install GPU than I expected and I share the several component that stood in my way.Â 
Â 
&lt;strong&gt;&lt;span style=&quot;color:red&quot;&gt;Written at Oct 24 2019, if you think this is deprecated, please do not have a leap of faith.&lt;/span&gt;&lt;/strong&gt;
Â 
Â Â Â Â Â Â &lt;/p&gt;

&lt;h3 id=&quot;1-did-not-know-there-is-jupyterlab-in-google-cloud-platform&quot;&gt;1. Did not know there is &lt;em&gt;JupyterLab&lt;/em&gt; in &lt;strong&gt;Google Cloud Platform&lt;/strong&gt;.&lt;/h3&gt;

&lt;p&gt;At the first time when GCP came out, there was no &lt;strong&gt;AI  Platform&lt;/strong&gt; service. So from starting vm instance to launching jupyter and installing packages, I did all of the things myself. (but I learned ğŸ¤—)&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/installing-conda-cli.png&quot; alt=&quot;installing-conda-cli&quot; /&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$	curl -O https://repo.continuum.io/archive/Anaconda3-5.0.1-Linux-x86_64.sh
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p align=&quot;center&quot;&gt;[Downloading conda in ssh]&lt;/p&gt;

&lt;p&gt;Â 
I created VM instance,selected zone, machine type and disk type. Then, define firewall rules and in ssh terminal, install jupyter and other packages.&lt;/p&gt;

&lt;p&gt;But you can do all of these things AI Platform.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/AI.png&quot; alt=&quot;installing-conda-cli&quot; /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;[AI Platform]&lt;/p&gt;

&lt;p&gt;I think if you are at Asia-Pacific, it can save your time.&lt;/p&gt;

&lt;p&gt;Â Â Â Â Â &lt;/p&gt;
&lt;h3 id=&quot;2-consider-if-the-platform-has-limited-resources-in-a-region-you-live-in&quot;&gt;2. Consider if the platform has limited resources in a region you live in.&lt;/h3&gt;
&lt;p&gt;Â 
I live in &lt;em&gt;South Korea, East Asia&lt;/em&gt;, and it seems like this region has lots of limitation in GPU (except quite expensive AWS).&lt;/p&gt;

&lt;p&gt;Â 
And the Taiwan which was the only one region where I can launch my own VM with GPU (I tried all the other regions in the list) sometimes do normaly, but not always. ğŸ˜¥&lt;/p&gt;

&lt;p&gt;Â 
After launching, I did several works and next day I could not start VM. (I didnâ€™t count it, but tried it a few hours because I didnâ€™t want cost any more timeâ€¦)&lt;/p&gt;

&lt;p&gt;Â 
Endlessly failed to start instance, then I choose to move AWS as an alternative way.&lt;/p&gt;

&lt;p&gt;Â Â Â Â Â &lt;/p&gt;
&lt;h3 id=&quot;3-fastai-gives-deliberate-guide-and-i-didnt-know-it&quot;&gt;3. &lt;span style=&quot;color:blue&quot;&gt;Fast.ai gives deliberate &lt;a href=&quot;https://course.fast.ai/start_gcp.html&quot;&gt;guide&lt;/a&gt; and I didnâ€™t know it.&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;Â 
Fast.ai offer the guide for all available platform. (Colab, salamander, Gradient, Kaggle, Colab, and so on)&lt;/p&gt;

&lt;p&gt;Â 
It is so important, and really needs, because cloud computing options are vary as occasion and purpose arise.&lt;/p&gt;

&lt;p&gt;Â 
I didnâ€™t know fast.ai has manual to running GCP, and I think itâ€™s as good a reason as any for me to be have taken time.&lt;/p&gt;

&lt;p&gt;Â 
It helped me so much when I had aws and shortened time.&lt;/p&gt;

&lt;p&gt;I donâ€™t want to read all of the manual in amazno.. (It is recommended.. but Iâ€™d rather read &lt;a href=&quot;https://git-scm.com/book/en/v2&quot;&gt;GIT PRO&lt;/a&gt; for nowâ€¦)
&lt;code&gt;ssh -i ~/.ssh/&lt;your_private_key_pair&gt; -L localhost:8888:localhost:8888 ubuntu@&lt;your instance=&quot;&quot; IP=&quot;&quot;&gt;&amp;lt;/code&amp;gt;&lt;/your&gt;&lt;/your_private_key_pair&gt;&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Â Â Â Â Â &lt;/p&gt;
&lt;h3 id=&quot;4-you-should-wait-to-add-more-volume-just-after-add-volume-by-building-aws-ec2&quot;&gt;4. You should wait to add more volume just after add volume, by building AWS EC2.&lt;/h3&gt;
&lt;p&gt;Â 
Since Elastic Block Store(EBS) storage supports optimized storage, users canâ€™t extend storage volume two times in a row.&lt;/p&gt;

&lt;p&gt;Â 
Unfortunately, at the first time, I didnâ€™t know it (again ğŸ‘») and when VM lacked volume, I doubled dist capacity (76*2) at a rough but It needs more.&lt;/p&gt;

&lt;p&gt;Â &lt;/p&gt;

&lt;!--# TODO

ê·¸ëƒ¥ ë” ì¶”ê°€í•˜ë©´ ë˜ê² ì§€ë¼ê³ ìƒê°í–ˆìœ¼ë‚˜ optimizing ì¤‘ì…ë‹ˆë‹¤.. ì•ˆë©ë‹ˆë‹¤ ë¼ê³  í–ˆë”° ã… 
ë§¨ ìœ„ì— ë‚´ê°€ ë­˜ ë­˜ í•´ë´¤ë˜ ì‚¬ëŒì¸ì§€  ì ê¸°. ì €ê¸° ì íŒ ê²ƒì¤‘ì—” Kaggle, Golab, google colud, Azure, amazon ec2ê°€ ìˆêµ°.--&gt;

&lt;p&gt;&amp;lt;!â€“&lt;/p&gt;

&lt;p&gt;this time I installed GPU in two years, and it became little complicated compared to 2 years ago.
And this time for the first time(maybe not the first time.. but i handled it in my class or with my friend. but itâ€™s my first time on my own.) I 
very Iâ€™m started to using used google colab, kaggle
and, GCP-JupyterLab, ec2 - friend made, 
aws vm machine but I had a environment variable but i did not know of it.
On these days, I could not get a resources from taiwanâ€¦&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;I couldnâ€™t notice a deliberate&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Anyway, as a result I tried myself gcp myself and aws ec2 with fast.ai But I think doing on my self surely takes much time (in this point I wonder why Iâ€™m doing this, and should remind me, especially I was studying disk volume optimization)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;h2 id=&quot;disk-volume-exceed---httpsaskubuntucomquestions919748no-space-left-on-device-even-though-there-is&quot;&gt;disk volume exceed - https://askubuntu.com/questions/919748/no-space-left-on-device-even-though-there-is&lt;/h2&gt;
  &lt;/li&gt;
&lt;/ol&gt;</content><author><name>dionne</name></author><category term="sticky" /><category term="featured" /><summary type="html">Motivation</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:4000/assets/images/asia-east1.png" /></entry><entry><title type="html">Lecture 08 - Deep Learning From Foundations-part1</title><link href="http://localhost:4000/2019/10/note08-fastai-1/" rel="alternate" type="text/html" title="Lecture 08 - Deep Learning From Foundations-part1" /><published>2019-10-18T00:00:00+09:00</published><updated>2019-10-18T00:00:00+09:00</updated><id>http://localhost:4000/2019/10/note08-fastai-1</id><content type="html" xml:base="http://localhost:4000/2019/10/note08-fastai-1/">&lt;p&gt;Â 
&lt;em&gt;I donâ€™t know if you read this article, but I heartily appreciate Rachael Thomas and Jeremy Howard for providing these priceless lectures for free&lt;/em&gt;
Â 
&lt;strong&gt;Contents&lt;/strong&gt;
Â 
1) &lt;a href=&quot;#whats-going-on-in-this-course&quot;&gt;What is going on in this course&lt;/a&gt;
2) &lt;a href=&quot;#library-development-using-jupyter-notebook&quot;&gt;Library development using jupyter notebook&lt;/a&gt;
Â 
&lt;strong&gt;Resources&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/fastai/course-v3/blob/master/nbs/dl2/01_matmul.ipynb&quot;&gt;notebooks&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://drive.google.com/file/d/18QwDI25Lf0ld0-cEugu7LxjwTc2NRkha/view&quot;&gt;material&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://course.fast.ai/videos/?lesson=8&quot;&gt;video&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://docs.google.com/spreadsheets/d/1bIPBcf-p9iqNG8BGmIVlJCFa4jEsbOZvcPXGTYe5pjI/edit#gid=0&quot;&gt;broadcasting excel&lt;/a&gt;
Â &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;what-is-going-on-in-this-course&quot;&gt;What is going on in this course?&lt;/h2&gt;

&lt;p&gt;Â &lt;/p&gt;
&lt;h4 id=&quot;what-is-from-foundations&quot;&gt;What is &lt;em&gt;â€˜from foundationsâ€™&lt;/em&gt;?&lt;/h4&gt;

&lt;p&gt;1) Recreate fast.ai and Pytorch&lt;/p&gt;

&lt;p&gt;2) using pure python
Â &lt;/p&gt;
&lt;h4 id=&quot;evade-overfitting&quot;&gt;Evade Overfitting&lt;/h4&gt;

&lt;p&gt;Overfit : validation error getting worse
&lt;del&gt;training loss &amp;lt; validation loss&lt;/del&gt;
Â &lt;/p&gt;
&lt;h4 id=&quot;know-the-name-of-the-symbol-you-use&quot;&gt;Know the name of the symbol you use&lt;/h4&gt;

&lt;p&gt;find in this page if you donâ€™t know the symbol that you are using&lt;a href=&quot;https://en.wikipedia.org/wiki/List_of_mathematical_symbols&quot;&gt;&lt;/a&gt; or just draw it &lt;a href=&quot;http://detexify.kirelabs.org/classify.html&quot;&gt;here&lt;/a&gt; (run by ML!)&lt;/p&gt;

&lt;h4 id=&quot;steps-to-a-basic-modern-cnn-model&quot;&gt;Steps to a basic modern CNN model&lt;/h4&gt;

&lt;blockquote&gt;
  &lt;p&gt;1) Matrix multiplication -&amp;gt; 2) Relu/Initialization -&amp;gt; 3) Fully-connected Forward
-&amp;gt; 4) Fully-connected Backward -&amp;gt; 5) Train loop -&amp;gt; 6) Convolution-&amp;gt; 7) Optimization -&amp;gt;
8) Batchnormalization -&amp;gt; 9) Resnet&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h4 id=&quot;todays-implementation-goal-1-matmul---4-fc-backward&quot;&gt;Todayâ€™s implementation goal: 1) matmul -&amp;gt; 4) FC backward&lt;/h4&gt;
&lt;p&gt;Â &lt;/p&gt;
&lt;h3 id=&quot;library-development-using-jupyter-notebook&quot;&gt;Library development using jupyter notebook&lt;/h3&gt;
&lt;p&gt;https://dbader.org/blog/python-assert-tutorial
Â &lt;/p&gt;
&lt;h4 id=&quot;jupyter-notebook-certainly-can-make-module&quot;&gt;jupyter notebook certainly can make module&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;There will be &lt;em&gt;#export&lt;/em&gt; tag that Howard (and we) want to extract&lt;/li&gt;
  &lt;li&gt;special &lt;em&gt;notebook2script.py&lt;/em&gt; will detect sign of &lt;em&gt;#expert&lt;/em&gt; and convert following into python module
Â &lt;/li&gt;
  &lt;li&gt;and test it&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;code&gt;test\_eq(TEST,'test')&amp;nbsp;test\_eq(TEST,'test1')&lt;/code&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;what is &lt;strong&gt;run_notebook.py&lt;/strong&gt;?
    &lt;ul&gt;
      &lt;li&gt;when you want to test your module in command line interface&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;code&gt;		!python run\_notebook.py 01_matmul.ipynb&lt;/code&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Is there any difference between 1) and 2)?&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;1) test -&amp;gt; test01 
2) test01 -&amp;gt; test&lt;/p&gt;

&lt;p&gt;#TODO I donâ€™t know yet&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;look into &lt;em&gt;run_notebook.py&lt;/em&gt;, package &lt;strong&gt;fire&lt;/strong&gt; Jeremy used. What is that?&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;read and run the code in a notebook, and in the process, Jeremy made &lt;a href=&quot;https://opensource.googleblog.com/2017/03/python-fire-command-line.html&quot;&gt;Python Fire&lt;/a&gt; library called!shockingly, fire takes any kind of function and converts into CLI command.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;fire library was released by Google open source, Thursday, March 2, 2017&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Â &lt;/p&gt;

&lt;h3 id=&quot;get-data&quot;&gt;Get data&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;pytorch and numpy are pretty much same.&lt;/li&gt;
  &lt;li&gt;variable c explains how many pixels there are in in MNIST, 28 pixels&lt;/li&gt;
  &lt;li&gt;PyTorchâ€™s &lt;em&gt;view()&lt;/em&gt; method: torch function that manipulating tensor, and squeeze() in torch &amp;amp; mathmatical operation similar function&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.oreilly.com/library/view/natural-language-processing/9781491978221/&quot;&gt;Rao &amp;amp; McMahan&lt;/a&gt; said usually this functions result in feature vector.&lt;/li&gt;
  &lt;li&gt;In part 1, you can use view function several times.
Â &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;initial-python-model&quot;&gt;Initial python model&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Which is Linear, like $Xw$(weight)$+a$(bias) $= Y$&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;If you donâ€™t know hou to multiple matrix, refer this site &lt;a href=&quot;http://matrixmultiplication.xyz&quot;&gt;matmul visulization site&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;how-many-time-spends-if-we-we-use-pure-python&quot;&gt;How many time spends if we we use pure python&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;function &lt;span style=&quot;color:blue&quot;&gt;matmul&lt;/span&gt;, typical matrix multiplication function, takes about 1 second for calculating 1 single train data! (maybe assumed stochastic, 5 data points in validation)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;it takes about 11.36 hours to update parameters even single layer and 1 iteration! (if that was my computer, it would be 14 hours..)ğŸ¤ª&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;THIS is why we need to consider â€˜timeâ€™&amp;amp;â€™spaceâ€™&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;This is kinda slow - what if we could speed it up by 50,000 times? Letâ€™s try!&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Â &lt;/p&gt;

&lt;h3 id=&quot;elementwise-ops&quot;&gt;Elementwise ops&lt;/h3&gt;

&lt;h4 id=&quot;how-can-we-make-python-faster&quot;&gt;How can we make python faster?&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;If we want to calculate faster, then do remove pythonic calcuation, by passing its computation down to something that is written something other than python, like pytorch.&lt;/li&gt;
  &lt;li&gt;According to PyTorch &lt;a href=&quot;https://pytorch.org/cppdocs/#aten&quot;&gt;doc&lt;/a&gt; it  uses C++ (via ATen), so we are going to implement that function with python.
Â &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/6.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;what-is-element-wise-operation&quot;&gt;What is element wise operation?&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;items makes a pair, operate corresponding component
Â &lt;/li&gt;
&lt;/ul&gt;</content><author><name>dionne</name></author><category term="featured" /><summary type="html">Â  I donâ€™t know if you read this article, but I heartily appreciate Rachael Thomas and Jeremy Howard for providing these priceless lectures for free Â  Contents Â  1) What is going on in this course 2) Library development using jupyter notebook Â  Resources notebooks material video broadcasting excel Â </summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:4000/assets/images/cnn.png" /></entry></feed>